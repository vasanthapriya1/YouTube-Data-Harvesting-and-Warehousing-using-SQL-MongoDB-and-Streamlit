# YouTube-Data-Harvesting-and-Warehousing-using-SQL-MongoDB-and-Streamlit
This project is a powerful Streamlit application designed to provide users with seamless access and analysis of data from multiple YouTube channels. This intuitive tool leverages the Google API to retrieve a comprehensive range of information, including channel details, video statistics, and viewer engagement metrics.

## Approach 

- Set up a Streamlit app.
- Connect to the YouTube API.
- Store data in a MongoDB.
- Migrate data to a SQL.
- Query the SQL db.
- Display data in the Streamlit app.

## Features

1. Retrieve data from the YouTube API, including channel information, playlists, videos, and comments.
2. Store the retrieved data in a MongoDB database.
3. Migrate the data to a SQL data warehouse.
4. Analyze and visualize data using Streamlit.
5. Perform queries on the SQL data warehouse.
6. Gain insights into channel performance, videos.

## Technology Used
1. Python 
2. MySQL
3. MongoDB
4. Google Client Library
5. Streamlit
6. Data collection
   
## Skills Developed:

1. Python Scripting:
- Utilize Python for scripting tasks, including interacting with APIs, data processing, and application development.

2. Data Collection:
- Learn effective methods for collecting data from external sources, specifically utilizing the YouTube API for retrieving channel details.

3. MongoDB:
- Acquire skills in working with MongoDB, a NoSQL database, for storing unstructured and semi-structured data efficiently.

4. Streamlit:
- Develop proficiency in building web applications using Streamlit, a Python library designed for rapid data app prototyping.

5. API Integration:
- Understand how to integrate external APIs (Google API for YouTube in this case) into your Python application to fetch real-time data.

6. Data Management (MongoDB Atlas):
- Learn data management concepts using MongoDB Atlas, a cloud-based database service, for storing and retrieving data.

7. SQL:
- Gain expertise in working with SQL databases (e.g., MySQL ) for structured data storage, querying, and data warehousing.

## Project Benefits:

**1. Practical Python Application:** Develop a real-world application integrating various Python skills.
**2.Data Warehousing Concepts:** Understand the process of warehousing data from diverse sources into structured SQL databases.
**3. API Integration Proficiency:** Gain practical experience in integrating and working with external APIs.
**4. NoSQL Database Handling:** Acquire skills in managing unstructured and semi-structured data in MongoDB.
**5. Data Visualization and Exploration:** Implement data visualization features in the Streamlit app for effective data exploration.

## Installation

To run this project, you need to install the following packages:

- pip install google-api-python-client
- pip install pymongo
- pip install pandas
- pip install psycopg2
- pip install streamlit

## Conclusion

This project provides a holistic learning experience covering Python scripting, data collection, database management, and web application development in the context of social media data. It serves as a practical application of skills applicable in data engineering, analytics, and web development domains.

## References

- **Streamlit Documentation:** https://docs.streamlit.io/
- **YouTube API Documentation:** https://developers.google.com/youtube
- **MongoDB Documentation:** https://www.mongodb.com/docs/
- **Python Documentation:** https://docs.python.org/3/







